{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrMd4s6qmVgS",
        "outputId": "cf71ce02-9600-44fc-8dd0-fdcca7533eed"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import yaml, os\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "8TJucH0Um141"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JhkEVBzBluhQ"
      },
      "outputs": [],
      "source": [
        "def configure_for_performance(ds, batch_size, mode):\n",
        "    ds = ds.cache()\n",
        "    if mode == 'train':\n",
        "        ds = ds.shuffle(buffer_size=1000)\n",
        "    ds = ds.batch(batch_size)\n",
        "    ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "class training_DataLoader():\n",
        "    def __init__(self, path_to_slakh, instr_class, batch_size = 8) -> None:\n",
        "        self.path_to_slakh = Path(path_to_slakh)\n",
        "        self.instr_class = instr_class\n",
        "        self.batch_size = batch_size\n",
        "        self.metadata_df = self.get_metadata()\n",
        "\n",
        "    def get_metadata(self):\n",
        "        metadata_df = pd.DataFrame(columns = ['mix_path'])\n",
        "        for i,path in enumerate(self.path_to_slakh.glob('**/metadata.yaml')):\n",
        "            root = path.parent\n",
        "            mix_path = root / 'mix.wav'\n",
        "            metadata_df.loc[i, 'mix_path'] = mix_path\n",
        "            metadata_path = root / 'metadata.yaml'\n",
        "            with open(metadata_path, 'r') as file:\n",
        "                metadata = yaml.safe_load(file)\n",
        "            j=0\n",
        "            for key in metadata['stems'].keys():\n",
        "                if metadata['stems'][key]['inst_class'] == self.instr_class:\n",
        "                    metadata_df.loc[i, f'instr_path_{j}'] = root / f'stems/{key}.wav'\n",
        "                    j+=1\n",
        "\n",
        "        return metadata_df\n",
        "\n",
        "    def get_data(self, indexes, mode):\n",
        "        first = True\n",
        "        for index, row in self.metadata_df.iloc[indexes].iterrows():\n",
        "            mix_path, instr_path = row['mix_path'], row['instr_path_0']\n",
        "\n",
        "            y_mix, sr = librosa.load(mix_path)\n",
        "            mean, stddev = np.mean(y_mix), np.std(y_mix)\n",
        "            y_mix = (y_mix-mean)/stddev\n",
        "\n",
        "            y_instr, sr = librosa.load(instr_path)\n",
        "            mean, stddev = np.mean(y_instr), np.std(y_instr)\n",
        "            y_instr = (y_instr-mean)/stddev\n",
        "\n",
        "            if first:\n",
        "                X_slices = tf.signal.frame(y_mix,\n",
        "                                          2**15,\n",
        "                                          2**13,\n",
        "                                          pad_end=True,\n",
        "                                          pad_value=0,\n",
        "                                          axis=-1)\n",
        "                y_slices = tf.signal.frame(y_instr,\n",
        "                                          2**15,\n",
        "                                          2**13,\n",
        "                                          pad_end=True,\n",
        "                                          pad_value=0,\n",
        "                                          axis=-1)\n",
        "\n",
        "                first = False\n",
        "\n",
        "            else:\n",
        "                frames_mix = tf.signal.frame(y_mix,\n",
        "                                            2**15,\n",
        "                                            2**14,\n",
        "                                            pad_end=True,\n",
        "                                            pad_value=0,\n",
        "                                            axis=-1)\n",
        "\n",
        "                X_slices = np.concatenate([X_slices,frames_mix], axis = 0)\n",
        "\n",
        "                frames_instr = tf.signal.frame(y_instr,\n",
        "                                              2**15,\n",
        "                                              2**14,\n",
        "                                              pad_end=True,\n",
        "                                              pad_value=0,\n",
        "                                              axis=-1)\n",
        "\n",
        "                y_slices = np.concatenate([y_slices,frames_instr], axis = 0)\n",
        "\n",
        "\n",
        "        X = tf.data.Dataset.from_tensor_slices(X_slices)\n",
        "        y = tf.data.Dataset.from_tensor_slices(y_slices)\n",
        "\n",
        "        return configure_for_performance(tf.data.Dataset.zip((X, y)), self.batch_size, mode)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import layers\n",
        "\n",
        "def downsample_block(x, n_filters):\n",
        "   # Conv2D then ReLU activation\n",
        "   x = layers.Conv2D(n_filters, 5,\n",
        "                     strides=2,\n",
        "                     padding='same',\n",
        "                     kernel_initializer = \"he_normal\")(x)\n",
        "   x = layers.BatchNormalization(axis=-1,\n",
        "                                 momentum=0.01,\n",
        "                                epsilon=1e-3)(x)\n",
        "   x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "   return x\n",
        "\n",
        "\n",
        "def upsample_block(x, conv_features, n_filters, dropout, activation_func):\n",
        "\n",
        "    # upsample\n",
        "    x = layers.Conv2DTranspose(n_filters, 5, strides=2, padding='same', kernel_initializer = \"he_normal\")(x)\n",
        "    if activation_func == 'relu':\n",
        "        x = layers.ReLU()(x)\n",
        "    elif activation_func == 'sigmoid':\n",
        "        x = keras.activations.sigmoid(x)\n",
        "    else:\n",
        "        pass\n",
        "    x = layers.BatchNormalization(axis=-1)(x)\n",
        "    # dropout\n",
        "    if dropout:\n",
        "        x = layers.Dropout(0.5)(x)\n",
        "    # concatenate\n",
        "    if conv_features != None:\n",
        "        x = layers.Concatenate(axis=-1)([x, conv_features])\n",
        "    return x\n",
        "\n",
        "def get_spectrogram(waveform):\n",
        "  # Convert the waveform to a spectrogram via a STFT.\n",
        "  spectrogram = tf.signal.stft(waveform, frame_length=512, frame_step=128, fft_length = 510, pad_end= True, window_fn=tf.signal.hamming_window)\n",
        "  # Add a `channels` dimension, so that the spectrogram can be used\n",
        "  # as image-like input data with convolution layers (which expect\n",
        "  # shape (`batch_size`, `height`, `width`, `channels`).\n",
        "  spectrogram = spectrogram[..., tf.newaxis]\n",
        "  return tf.math.log1p(tf.abs(spectrogram)), tf.math.angle(spectrogram)\n",
        "\n",
        "def build_unet_stft_model():\n",
        "    # inputs\n",
        "    inputs = layers.Input(shape=(2**15)) # ceil(log2(22050)) = 15 is the sampling rate of my training set and also half the sampling rate of standard CD quality\n",
        "\n",
        "    mag_spec, angle_spec = get_spectrogram(inputs)\n",
        "\n",
        "    # # #Normalize spectrograms\n",
        "    # bn_layer = layers.BatchNormalization(axis=-1)\n",
        "    # x = bn_layer(mag_spec)\n",
        "    # # Retrieve the mean and standard deviation learned by the BatchNormalization layer\n",
        "    # mean = bn_layer.get_weights()[0]\n",
        "    # std = bn_layer.get_weights()[1]\n",
        "\n",
        "\n",
        "    # encoder: contracting path - downsample\n",
        "    p1 = downsample_block(mag_spec, 16)\n",
        "    # 2 - downsample\n",
        "    p2 = downsample_block(p1, 32)\n",
        "    # 3 - downsample\n",
        "    p3 = downsample_block(p2, 64)\n",
        "    # 4 - downsample\n",
        "    p4 = downsample_block(p3, 128)\n",
        "    p5 = downsample_block(p4, 256)\n",
        "    # 5 - bottleneck\n",
        "    bottleneck = downsample_block(p5, 512)\n",
        "    # decoder: expanding path - upsample\n",
        "    # 1 - upsample\n",
        "    u1 = upsample_block(bottleneck, p5, 256, True, 'relu')\n",
        "    # 2 - upsample\n",
        "    u2 = upsample_block(u1, p4, 128, True, 'relu')\n",
        "    # 3 - upsample\n",
        "    u3 = upsample_block(u2, p3, 64, False, 'relu')\n",
        "    # 4 - upsample\n",
        "    u4 = upsample_block(u3, p2, 32, False, 'relu')\n",
        "    # 5 - upsample\n",
        "    u5 = upsample_block(u4, p1, 16, False, 'relu')\n",
        "    # 6 - upsample\n",
        "    u6 = upsample_block(u5, None, 1, False, 'relu')\n",
        "    u7 = layers.Conv2D(\n",
        "            1,\n",
        "            (4, 4),\n",
        "            dilation_rate=(2, 2),\n",
        "            activation=\"sigmoid\",\n",
        "            padding=\"same\",\n",
        "            kernel_initializer=\"he_normal\")(u6)\n",
        "\n",
        "    # outputs (signal_reconstruction)\n",
        "    outputs_mag_spec = tf.math.expm1(layers.Multiply()([u7, mag_spec]))\n",
        "    outputs_spec = tf.math.multiply(tf.cast(outputs_mag_spec, tf.complex64), tf.complex(tf.cos(angle_spec),tf.sin(angle_spec)))\n",
        "    outputs = tf.signal.inverse_stft(tf.squeeze(outputs_spec, axis=-1), frame_length=512, frame_step=128, fft_length = 510,\n",
        "                                     window_fn=tf.signal.inverse_stft_window_fn(128, forward_window_fn=tf.signal.hamming_window))[:,:inputs.shape[1]]\n",
        "\n",
        "\n",
        "    # unet model with Keras Functional API\n",
        "    unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n",
        "    unet_model.compile(optimizer=\"adam\",\n",
        "                        loss=tf.keras.metrics.mean_absolute_error)\n",
        "\n",
        "    return unet_model"
      ],
      "metadata": {
        "id": "4UodqnKFtxz7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.backend as K\n",
        "import gc\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# USE MULTIPLE GPUS\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if len(gpus)<=1:\n",
        "    strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n",
        "    print(f'Using {len(gpus)} GPU')\n",
        "else:\n",
        "    strategy = tf.distribute.MirroredStrategy()\n",
        "    print(f'Using {len(gpus)} GPUs')\n",
        "\n",
        "EPOCHS = 5\n",
        "n_folds = 5\n",
        "instr_class = 'Drums'\n",
        "\n",
        "dataset = training_DataLoader('/content/drive/MyDrive/babyslakh', instr_class)\n",
        "\n",
        "gkf = KFold(n_splits=n_folds)\n",
        "\n",
        "for i, (train_index, valid_index) in enumerate(gkf.split(dataset.metadata_df)):\n",
        "\n",
        "    print('#'*25)\n",
        "    print(f'### Fold {i+1}')\n",
        "    print('#'*25)\n",
        "\n",
        "    train_ds = dataset.get_data(train_index, 'train')\n",
        "    val_ds = dataset.get_data(valid_index, 'test')\n",
        "\n",
        "    with strategy.scope():\n",
        "        model = build_unet_stft_model()\n",
        "\n",
        "    model.fit(train_ds, verbose=1,\n",
        "              validation_data = val_ds,\n",
        "              epochs=EPOCHS,\n",
        "              batch_size=8)#, callbacks = [LR] )\n",
        "    model.save_weights(f'Unet_{instr_class}_f{i}.h5')\n",
        "\n",
        "    K.clear_session()\n",
        "    del model\n",
        "    del train_ds\n",
        "    del val_ds\n",
        "    gc.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPREFvFzuT8a",
        "outputId": "2cf6c8ed-5b89-49f4-f3ff-ede8df1532b0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 1 GPU\n",
            "#########################\n",
            "### Fold 1\n",
            "#########################\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "702/702 [==============================] - 29s 22ms/step - loss: 0.2950 - val_loss: 0.3568\n",
            "Epoch 2/5\n",
            "702/702 [==============================] - 14s 20ms/step - loss: 0.2662 - val_loss: 0.3479\n",
            "Epoch 3/5\n",
            "702/702 [==============================] - 14s 20ms/step - loss: 0.2594 - val_loss: 0.3346\n",
            "Epoch 4/5\n",
            "702/702 [==============================] - 14s 20ms/step - loss: 0.2562 - val_loss: 0.3447\n",
            "Epoch 5/5\n",
            "702/702 [==============================] - 14s 19ms/step - loss: 0.2534 - val_loss: 0.3426\n",
            "#########################\n",
            "### Fold 2\n",
            "#########################\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "706/706 [==============================] - 22s 22ms/step - loss: 0.2974 - val_loss: 0.3076\n",
            "Epoch 2/5\n",
            "706/706 [==============================] - 14s 19ms/step - loss: 0.2741 - val_loss: 0.2978\n",
            "Epoch 3/5\n",
            "706/706 [==============================] - 14s 19ms/step - loss: 0.2682 - val_loss: 0.2936\n",
            "Epoch 4/5\n",
            "706/706 [==============================] - 14s 19ms/step - loss: 0.2641 - val_loss: 0.2962\n",
            "Epoch 5/5\n",
            "706/706 [==============================] - 14s 20ms/step - loss: 0.2619 - val_loss: 0.2908\n",
            "#########################\n",
            "### Fold 3\n",
            "#########################\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "693/693 [==============================] - 22s 21ms/step - loss: 0.2924 - val_loss: 0.3160\n",
            "Epoch 2/5\n",
            "693/693 [==============================] - 14s 20ms/step - loss: 0.2705 - val_loss: 0.3115\n",
            "Epoch 3/5\n",
            "693/693 [==============================] - 13s 19ms/step - loss: 0.2651 - val_loss: 0.3112\n",
            "Epoch 4/5\n",
            "693/693 [==============================] - 14s 20ms/step - loss: 0.2616 - val_loss: 0.3084\n",
            "Epoch 5/5\n",
            "693/693 [==============================] - 14s 19ms/step - loss: 0.2591 - val_loss: 0.3175\n",
            "#########################\n",
            "### Fold 4\n",
            "#########################\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "669/669 [==============================] - 21s 22ms/step - loss: 0.3271 - val_loss: 0.2597\n",
            "Epoch 2/5\n",
            "669/669 [==============================] - 14s 20ms/step - loss: 0.3043 - val_loss: 0.2551\n",
            "Epoch 3/5\n",
            "669/669 [==============================] - 13s 20ms/step - loss: 0.2948 - val_loss: 0.2580\n",
            "Epoch 4/5\n",
            "669/669 [==============================] - 13s 20ms/step - loss: 0.2890 - val_loss: 0.2572\n",
            "Epoch 5/5\n",
            "669/669 [==============================] - 13s 20ms/step - loss: 0.2852 - val_loss: 0.2540\n",
            "#########################\n",
            "### Fold 5\n",
            "#########################\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "673/673 [==============================] - 22s 22ms/step - loss: 0.3048 - val_loss: 0.3420\n",
            "Epoch 2/5\n",
            "673/673 [==============================] - 14s 20ms/step - loss: 0.2769 - val_loss: 0.3366\n",
            "Epoch 3/5\n",
            "673/673 [==============================] - 13s 20ms/step - loss: 0.2698 - val_loss: 0.3334\n",
            "Epoch 4/5\n",
            "673/673 [==============================] - 14s 20ms/step - loss: 0.2666 - val_loss: 0.3308\n",
            "Epoch 5/5\n",
            "673/673 [==============================] - 14s 20ms/step - loss: 0.2643 - val_loss: 0.3357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "for i in range(5):\n",
        "  files.download(f'Unet_{instr_class}_f{i}.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "e8XkoxydW9Gt",
        "outputId": "201ae7e4-57ef-49cd-e81a-75f538ac0147"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cf2dfbdf-3e62-4f7a-971a-3d480091af93\", \"Unet_Drums_f0.h5\", 39428656)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9b610135-737f-4247-aa5e-e9be9b509cdd\", \"Unet_Drums_f1.h5\", 39428656)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0a4e0700-c9ea-41ec-9136-79235b5611bc\", \"Unet_Drums_f2.h5\", 39428656)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5e6e3c33-1071-4f99-afc2-c0ce0c840276\", \"Unet_Drums_f3.h5\", 39428656)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_15f8c7d2-3d3c-4f8a-b1f2-dd8ac3b61522\", \"Unet_Drums_f4.h5\", 39428656)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import soundfile as sf\n",
        "\n",
        "class predict_DataLoader():\n",
        "    def __init__(self, path_to_file, batch_size = 8) -> None:\n",
        "        self.path_to_file = path_to_file\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def get_data(self):\n",
        "\n",
        "        y, sr = librosa.load(self.path_to_file)\n",
        "        self.len_signal = len(y)\n",
        "\n",
        "        if sr != 22050:\n",
        "          y = librosa.resample( y, orig_sr = sr, target_sr = 22050)\n",
        "\n",
        "        mean, stddev = np.mean(y), np.std(y)\n",
        "        y = (y-mean)/stddev\n",
        "\n",
        "\n",
        "        X = tf.signal.frame(y,\n",
        "                            2**15,\n",
        "                            2**13,\n",
        "                            pad_end=True,\n",
        "                            pad_value=0,\n",
        "                            axis=-1)\n",
        "\n",
        "        return configure_for_performance(tf.data.Dataset.from_tensor_slices(X), self.batch_size, 'test'), mean, stddev\n",
        "\n",
        "\n",
        "def get_signal_from_frames(Frames, step_size, input_signal_len):\n",
        "    y = []\n",
        "    for i in range(Frames.shape[0]):\n",
        "        frame = Frames[i,:]\n",
        "        for j in range(frame.shape[0]):\n",
        "            timestep_frame = frame[j]\n",
        "            id = i*step_size + j\n",
        "            if len(y) <= id:\n",
        "                y.append([timestep_frame])\n",
        "            else:\n",
        "                (y[id]).append(timestep_frame)\n",
        "\n",
        "    signal = []\n",
        "    for i in range(len(y)):\n",
        "        signal.append(np.mean(y[i]))\n",
        "    signal = np.array(signal)[:input_signal_len]\n",
        "    return signal\n",
        "\n",
        "\n",
        "\n",
        "def predict(wav_path, model_weights_paths):\n",
        "\n",
        "    data_loader = predict_DataLoader(wav_path)\n",
        "    X, mean, stddev = data_loader.get_data()\n",
        "    print(mean, stddev)\n",
        "    len_input_signal = data_loader.len_signal\n",
        "\n",
        "    signals = []\n",
        "    for i, model_path in enumerate(model_weights_paths):\n",
        "        model = build_unet_stft_model()\n",
        "        model.load_weights(model_path)\n",
        "\n",
        "        y = model.predict(X)\n",
        "        signals.append(get_signal_from_frames(y, 2**13, len_input_signal))\n",
        "\n",
        "    signal = np.mean(np.array(signals), axis = 0)*stddev + mean\n",
        "    return signal\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "signals = predict('/content/drive/MyDrive/test_music/Dani_California.wav', [f'/content/drive/MyDrive/music_seg_models/Unet_Drums_f{i}.h5' for i in range(5)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_B30Fgqzunk7",
        "outputId": "a6e54d0d-1553-4954-d90f-13fe718e43a1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-9.960328e-06 0.29883942\n",
            "95/95 [==============================] - 1s 5ms/step\n",
            "95/95 [==============================] - 1s 5ms/step\n",
            "95/95 [==============================] - 1s 5ms/step\n",
            "95/95 [==============================] - 1s 5ms/step\n",
            "95/95 [==============================] - 1s 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sf.write('Dani_California_drums_5folds.wav', signals, 22050, subtype='PCM_24')\n",
        "files.download('Dani_California_drums_5folds.wav')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "np5fvgzfgIuC",
        "outputId": "0d5c4a9f-2461-429c-ee95-cb91d33efebb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_89785717-423d-454f-9974-4382c363574a\", \"Dani_California_drums_5folds.wav\", 18664928)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}